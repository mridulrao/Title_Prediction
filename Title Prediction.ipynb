{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c09cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52979c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greens say no support for Macron's EZ budget i...</td>\n",
       "      <td>BERLIN (Reuters) - None of the German parties ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 25, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump faces uphill battle to overcome court's ...</td>\n",
       "      <td>(Reuters) - U.S. President Donald Trump faces ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 6, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ukraine president denies hampering anti-corrup...</td>\n",
       "      <td>VILNIUS/KIEV (Reuters) - Ukrainian President P...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>December 8, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U.S. defense chief: White House shakeup will n...</td>\n",
       "      <td>BRUSSELS (Reuters) - U.S. Defense Secretary Ji...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 14, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Irish government set to fall weeks before Brex...</td>\n",
       "      <td>DUBLIN (Reuters) - Ireland s minority governme...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 24, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Greens say no support for Macron's EZ budget i...   \n",
       "1  Trump faces uphill battle to overcome court's ...   \n",
       "2  Ukraine president denies hampering anti-corrup...   \n",
       "3  U.S. defense chief: White House shakeup will n...   \n",
       "4  Irish government set to fall weeks before Brex...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  BERLIN (Reuters) - None of the German parties ...     worldnews   \n",
       "1  (Reuters) - U.S. President Donald Trump faces ...  politicsNews   \n",
       "2  VILNIUS/KIEV (Reuters) - Ukrainian President P...     worldnews   \n",
       "3  BRUSSELS (Reuters) - U.S. Defense Secretary Ji...  politicsNews   \n",
       "4  DUBLIN (Reuters) - Ireland s minority governme...     worldnews   \n",
       "\n",
       "                 date  \n",
       "0   October 25, 2017   \n",
       "1   February 6, 2017   \n",
       "2   December 8, 2017   \n",
       "3  February 14, 2017   \n",
       "4  November 24, 2017   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6b6512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['worldnews', 'politicsNews'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d410ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_world_news = pd.DataFrame(columns = [\"title\", \"text\"])\n",
    "df_politics_news = pd.DataFrame(columns = [\"title\", \"text\"])\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df['subject'].iloc[i] == 'worldnews':\n",
    "        row = pd.Series({'title' : df['title'].iloc[i], 'text' : df['text'].iloc[i]})\n",
    "        df_world_news = pd.concat([df_world_news, row.to_frame().T], ignore_index = True)\n",
    "    else:\n",
    "        row = pd.Series({'title' : df['title'].iloc[i], 'text' : df['text'].iloc[i]})\n",
    "        df_politics_news = pd.concat([df_politics_news, row.to_frame().T], ignore_index = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d0d7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greens say no support for Macron's EZ budget i...</td>\n",
       "      <td>BERLIN (Reuters) - None of the German parties ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ukraine president denies hampering anti-corrup...</td>\n",
       "      <td>VILNIUS/KIEV (Reuters) - Ukrainian President P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Irish government set to fall weeks before Brex...</td>\n",
       "      <td>DUBLIN (Reuters) - Ireland s minority governme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Northern Ireland fears Brexit loss of EU peace...</td>\n",
       "      <td>BELFAST (Reuters) - The European Union has lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mexican governor requests leave to run for pre...</td>\n",
       "      <td>MEXICO CITY (Reuters) - The governor of Nuevo ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Greens say no support for Macron's EZ budget i...   \n",
       "1  Ukraine president denies hampering anti-corrup...   \n",
       "2  Irish government set to fall weeks before Brex...   \n",
       "3  Northern Ireland fears Brexit loss of EU peace...   \n",
       "4  Mexican governor requests leave to run for pre...   \n",
       "\n",
       "                                                text  \n",
       "0  BERLIN (Reuters) - None of the German parties ...  \n",
       "1  VILNIUS/KIEV (Reuters) - Ukrainian President P...  \n",
       "2  DUBLIN (Reuters) - Ireland s minority governme...  \n",
       "3  BELFAST (Reuters) - The European Union has lon...  \n",
       "4  MEXICO CITY (Reuters) - The governor of Nuevo ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_world_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "963e002c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BERLIN (Reuters) - None of the German parties involved in exploratory coalition talks support French President Emmanuel Macron s idea to create a separate budget for the euro zone, a negotiator for the Greens party told Reuters on Wednesday. Reinhard Buetikofer, who participated in a late-night negotiating session on European policy on Tuesday with German Chancellor Angela Merkel s conservatives and the Free Democrats (FDP), said the Greens supported the idea of more investment in infrastructure but not a new budget.  None of the participating parties support a euro zone budget,  Buetikofer, a member of the European Parliament said.  We Greens fully support the idea of finding ways, within the framework of the existing EU budget, to boost investment in infrastructure. We share Macron s aim of increasing investment.  The news is a blow to Macron, who has called for the creation of a euro zone budget of several hundred billions of euros to help the single currency bloc cope with economic shocks. The Greens are seen as the biggest supporters of Macron s ideas among the German parties considering a coalition.  '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_world_news['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a7a89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df_world_news['text']\n",
    "target_data = df_world_news['title']\n",
    "\n",
    "target_data_appended = []\n",
    "\n",
    "#append sos and eos \n",
    "for sentence in target_data:\n",
    "    target_data_appended.append(\"sos \" + sentence + \" eos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab385772",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text = 1000 \n",
    "max_title = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c1e3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb9db1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43159\n"
     ]
    }
   ],
   "source": [
    "#text processing\n",
    "\n",
    "x = input_data\n",
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x))\n",
    "\n",
    "x_seq = x_tokenizer.texts_to_sequences(x) \n",
    "x_pad_seq = pad_sequences(x_seq, maxlen = max_text, padding='post') \n",
    "\n",
    "x_voc_size = len(x_tokenizer.word_index) +1\n",
    "print(x_voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "781c74b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9173\n"
     ]
    }
   ],
   "source": [
    "#title processing\n",
    "\n",
    "y = target_data_appended\n",
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y))\n",
    "\n",
    "y_seq = y_tokenizer.texts_to_sequences(y) \n",
    "y_pad_seq = pad_sequences(y_seq, maxlen = max_title, padding='post') \n",
    "\n",
    "y_voc_size = len(y_tokenizer.word_index) +1\n",
    "print(y_voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c70c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional, Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ccdc0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_20 (InputLayer)          [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_16 (Embedding)       (None, 1000, 256)    11048704    ['input_20[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_28 (LSTM)                 [(None, 1000, 256),  525312      ['embedding_16[0][0]']           \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " input_21 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_29 (LSTM)                 [(None, 1000, 256),  525312      ['lstm_28[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " embedding_17 (Embedding)       (None, None, 256)    2348288     ['input_21[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_30 (LSTM)                 [(None, 1000, 256),  525312      ['lstm_29[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_32 (LSTM)                 [(None, None, 256),  525312      ['embedding_17[0][0]',           \n",
      "                                 (None, 256),                     'lstm_30[1][1]',                \n",
      "                                 (None, 256)]                     'lstm_30[1][2]']                \n",
      "                                                                                                  \n",
      " attention_7 (Attention)        (None, None, 256)    0           ['lstm_32[0][0]',                \n",
      "                                                                  'lstm_30[1][0]']                \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 512)    0           ['lstm_32[0][0]',                \n",
      "                                                                  'attention_7[0][0]']            \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, None, 9173)   4705749     ['concat_layer[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,203,989\n",
      "Trainable params: 20,203,989\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# encoder \n",
    "encoder_inputs = Input(shape=(max_text,)) \n",
    "enc_emb = Embedding(x_voc_size, 256)(encoder_inputs)\n",
    "\n",
    "encoder_lstm1 = LSTM(256, return_sequences=True, return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) #lstm_1 output \n",
    "\n",
    "encoder_lstm2 = LSTM(256,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) #lstm_2 output \n",
    "\n",
    "encoder_lstm3 = LSTM(256,return_sequences=True,return_state=True) \n",
    "encoder_output3, state_h3, state_c3 = encoder_lstm3(encoder_output2) #lstm_3 output \n",
    "\n",
    "encoder_lstm4 = LSTM(256,return_sequences=True,return_state=True) \n",
    "encoder_output4, state_h4, state_c4 = encoder_lstm3(encoder_output2) #lstm_4 output \n",
    "\n",
    "#decoder\n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_voc_size, 256) \n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True) \n",
    "decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state=[state_h4, state_c4]) \n",
    "\n",
    "#Attention Layer\n",
    "attn_layer = Attention() \n",
    "attn_out = attn_layer([decoder_outputs, encoder_output4]) \n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "decoder_dense = Dense(y_voc_size, activation='softmax') \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff3841d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a929242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad array of 0's if the length is less than the maximum length \n",
    "#en_in_data= pad_sequences(x_train,  maxlen=max_in_len, padding='post') \n",
    "#dec_data= pad_sequences(y_train,  maxlen=max_tr_len, padding='post')\n",
    " \n",
    "dec_in = y_pad_seq[:, :-1]\n",
    "dec_out = y_pad_seq.reshape(len(y_pad_seq),max_title,1)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d83e3fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 02:56:48.315535: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - ETA: 0s - loss: 7.0576 - accuracy: 0.1322"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 03:04:31.361834: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 496s 10s/step - loss: 7.0576 - accuracy: 0.1322 - val_loss: 6.7907 - val_accuracy: 0.1355\n",
      "Epoch 2/5\n",
      "49/51 [===========================>..] - ETA: 19s - loss: 6.5821 - accuracy: 0.1432"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_pad_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_in\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdec_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit( \n",
    "    [x_pad_seq, dec_in],\n",
    "    dec_out, \n",
    "    batch_size=128, \n",
    "    epochs=5, \n",
    "    validation_split=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e093a4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 02:45:33.085616: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x2918e76a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x291975310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x29197c0d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x28b618790> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"title_predictor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b620315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ce9a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(\"title_predictor\")\n",
    "\n",
    "en_outputs, state_h_enc, state_c_enc = model.layers[6].output\n",
    "en_states = [state_h_enc,state_c_enc]\n",
    "\n",
    "en_model = Model(model.input[0], [en_outputs]+en_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f41dc337",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_state_input_h = Input(shape=(5,))\n",
    "dec_state_input_c = Input(shape=(5,))\n",
    "\n",
    "dec_hidden_state_input = Input(shape=(max_text, 5))\n",
    " \n",
    "dec_inputs = model.input[1]\n",
    "dec_emb_layer = model.layers[5]\n",
    "dec_lstm = model.layers[7]\n",
    "dec_embedding= dec_emb_layer(dec_inputs)\n",
    " \n",
    "dec_outputs2, state_h2, state_c2 = dec_lstm(dec_embedding, initial_state = [dec_state_input_h, dec_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d278d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = model.layers[8]\n",
    "attn_out2 = attention([dec_outputs2, dec_hidden_state_input])\n",
    " \n",
    "merge2 = Concatenate(axis=-1)([dec_outputs2, attn_out2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82ab20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_dense = model.layers[10]\n",
    "dec_outputs2 = dec_dense(merge2)\n",
    " \n",
    "\n",
    "dec_model = Model( [dec_inputs] + [dec_hidden_state_input,dec_state_input_h,dec_state_input_c], [dec_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19cd3975",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index = y_tokenizer.index_word\n",
    "reverse_source_word_index = x_tokenizer.index_word\n",
    "target_word_index = y_tokenizer.word_index\n",
    "reverse_target_word_index[0]=' '\n",
    " \n",
    "def decode_sequence(input_seq):\n",
    "    en_out, en_h, en_c= en_model.predict(input_seq)\n",
    " \n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = target_word_index['sos']\n",
    " \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    \n",
    "    while not stop_condition: \n",
    "        output_words, dec_h, dec_c= dec_model.predict([target_seq] + [en_out,en_h, en_c])\n",
    "        \n",
    "        word_index = np.argmax(output_words[0, -1, :])\n",
    "        text_word = reverse_target_word_index[word_index]\n",
    "        decoded_sentence += text_word +\" \"\n",
    "        \n",
    "        if text_word == \"eos\" or len(decoded_sentence) > max_title:\n",
    "            stop_condition = True\n",
    "\n",
    "            \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = word_index\n",
    "        en_h, en_c = dec_h, dec_c\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bf2e07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter : Generate title for this text\n",
      "Review : Generate title for this text\n",
      "\n",
      "Predicted summary: to to to to \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inp_review = input(\"Enter : \")\n",
    "inp_x = x_tokenizer.texts_to_sequences([inp_review]) \n",
    "inp_x = pad_sequences(inp_x,  maxlen = max_text, padding='post')\n",
    " \n",
    "title = decode_sequence(inp_x.reshape(1,max_text))\n",
    "\n",
    "if 'eos' in summary :\n",
    "    title = title.replace('eos','')\n",
    "    \n",
    "print(\"Title : \", title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e6dd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
